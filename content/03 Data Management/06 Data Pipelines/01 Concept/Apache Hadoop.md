# Apache Hadoop

> <- Back to [[Batch Processing]]

Open source framework for distributed batch processing of large datasets. Core components: MapReduce (processing), HDFS (storage), and YARN (resource management).

## Key Properties

- [[MapReduce]]
- [[HDFS]]
- [[YARN]]

---

#data-pipelines #batch #hadoop
