# Serving Frameworks

> <- Back to [[Model Serving]]

Tools for deploying and serving ML models in production. TorchServe (PyTorch), TensorFlow Serving (TF), Triton Inference Server (NVIDIA, multi-framework), BentoML (framework-agnostic, containerized).

## Related

- [[Real-Time Inference]] (what these frameworks enable)
- [[Model Optimization]] (optimize before serving)

---

#mlops #serving #frameworks
