# Edge Deployment

> <- Back to [[Model Serving]]

Running models on edge devices (phones, IoT, embedded systems) rather than cloud servers. Requires aggressive model optimization. Key tools: TensorFlow Lite, Core ML (Apple), ONNX Mobile.

## Related

- [[Model Optimization]] (required for edge)
- [[Real-Time Inference]] (ultra-low latency)

---

#mlops #edge #mobile #deployment
